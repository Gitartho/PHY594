{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 494/594\n",
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./include/header.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import trange,tqdm\n",
    "sys.path.append('./include')\n",
    "import ml4s\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('./include/notebook.mplstyle')\n",
    "np.set_printoptions(linewidth=120)\n",
    "ml4s.set_css_style('./include/bootstrap.css')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Notebook\n",
    "\n",
    "### [Notebook Link: 18_Introduction_to_Keras.ipynb](./18_Introduction_to_Keras.ipynb)\n",
    "\n",
    "- Learn how to use the `keras` and `tensorflow` libraries to build sequential deep neural networks.\n",
    "- Learn a simple 2D logical function\n",
    "\n",
    "### Last Time\n",
    "- Derived a new cost function for classificaiton tasks: **the binary cross-entropy**\n",
    "\n",
    "\\begin{equation}\n",
    "C(\\boldsymbol{w})=-\\frac{1}{N} \\sum_{n=1}^{N}\\left[y^{(n)} \\ln a^{L}+\\left(1-y^{(n)}\\right) \\ln \\left(1-a^{L}\\right)\\right]\n",
    "\\end{equation}\n",
    "\n",
    "## Today\n",
    "\n",
    "- Study a new type of problems involving the classification of inputs (map continue/discrete inputs into discrete outputs)\n",
    "- New cost functions: binary and categorical cross-entropy\n",
    "\n",
    "### Import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall our Rectangle Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "x = [0,0,0,1,1,0,1,1,0]\n",
    "\n",
    "def print_rectangle(x):\n",
    "    print(''.join([ci if (i+1)%L else ci+'\\n' for i,ci in \n",
    "                 enumerate([' ▉ ' if cx else ' ░ ' for i,cx in enumerate(x)])]))\n",
    "print_rectangle(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all possible configurations\n",
    "\n",
    "I have generated all $2^9 = 512$ configuration vectors and provided them with lables in a file `../data/rectangles_3x3.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../data/rectangles_3x3.dat')\n",
    "rectangles = data[:,:-1].astype(dtype=float)\n",
    "labels = data[:,-1].astype(dtype=int)\n",
    "\n",
    "print(f'Num rectangles/total = {np.sum(labels)}/{2**(L*L)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a difficult classification problem, as we can immediately achieve **94%** accuracy by just saying there are no rectangles!\n",
    "### Plot all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig,ax = plt.subplots(ncols=16,nrows=32,figsize=(16,32))\n",
    "axes = ax.flatten()\n",
    "cmaps = ['binary', 'Oranges']\n",
    "for i,cax in enumerate(ax.flatten()):\n",
    "    cax.matshow(rectangles[i,:].reshape(L,L), cmap=cmaps[labels[i]],vmin=0,vmax=1)\n",
    "    cax.set_xticks([])\n",
    "    cax.set_yticks([])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataset\n",
    "\n",
    "We do our usual 90/10 train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(rectangles, labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup our network\n",
    "\n",
    "In order to use the `binary_crossentropy` we need our output layer to have a single neuron and include `sigmoid` activation.\n",
    "\n",
    "<!--\n",
    "model = keras.Sequential(\n",
    "[\n",
    "    layers.Dense(128,input_shape=(L*L,),activation='selu', kernel_initializer='lecun_normal'),\n",
    "    layers.Dense(256,activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(256,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(l2=1e-2)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "[\n",
    "    layers.Dense(4,input_shape=(L*L,),activation='relu'),\n",
    "    layers.Dense(16,activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the cost function (loss) and optimizer\n",
    "\n",
    "**Note:** We have a new metric, which is `accuracy` or how many inputs were classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 32\n",
    "\n",
    "training_history = {}\n",
    "training_history['test'] = model.fit(x_train,y_train, epochs=epochs,validation_data=(x_test,y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into training history\n",
    "fig,ax = plt.subplots(2,1, sharex=True, sharey=True, figsize=(5,5))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax[0].plot(training_history['test'].history['accuracy'])\n",
    "ax[0].plot(training_history['test'].history['val_accuracy'], ls='--', color=colors[-3])\n",
    "ax[0].set_ylabel('model accuracy')\n",
    "ax[0].legend(['train', 'test'], loc='best')\n",
    "ax[0].set_ylim(0,1)\n",
    "\n",
    "# summarize history for loss\n",
    "ax[1].plot(training_history['test'].history['loss'])\n",
    "ax[1].plot(training_history['test'].history['val_loss'], ls='--', color=colors[-3])\n",
    "ax[1].set_ylabel('model loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['train', 'test'], loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate where the network is making mistakes\n",
    "\n",
    "We chose a *threshold probability* of 0.5 for our classification.  Mistakes occuren when the label and prediction disagree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "predictions = np.zeros(rectangles.shape[0],dtype=int)\n",
    "predictions[np.where(model(rectangles)>=0.6)[0]] = 1\n",
    "\n",
    "mistakes = np.where(labels != predictions)[0]\n",
    "num_mistakes = len(mistakes)\n",
    "\n",
    "print(f'Num. Mistakes  = {num_mistakes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a Confusion Matrix\n",
    "\n",
    "This is the standard approach to getting a broad view of how well your classifier is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "cm_display = ConfusionMatrixDisplay(cm,display_labels=['No Rectangle','Rectangle']).plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the configurations that were misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 16\n",
    "num_rows = num_mistakes//num_cols + 1\n",
    "cmaps = ['binary', 'Oranges']\n",
    "\n",
    "fig,ax = plt.subplots(ncols=num_cols,nrows=num_rows,figsize=(num_cols,num_rows))\n",
    "for i,cax in enumerate(ax.flatten()):\n",
    "    if i < len(mistakes):\n",
    "        idx = mistakes[i]\n",
    "        cax.matshow(rectangles[idx,:].reshape(L,L), cmap=cmaps[labels[idx]],vmin=0,vmax=1)\n",
    "        cax.set_xticks([])\n",
    "        cax.set_yticks([])\n",
    "    else:\n",
    "        cax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
