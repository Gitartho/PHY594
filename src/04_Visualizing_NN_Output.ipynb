{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 494/594\n",
    "## Building a Feed Forward Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./include/header.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import trange,tqdm\n",
    "sys.path.append('./include')\n",
    "import ml4s\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('./include/notebook.mplstyle')\n",
    "np.set_printoptions(linewidth=120)\n",
    "ml4s.set_css_style('./include/bootstrap.css')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Time\n",
    "\n",
    "### [Notebook Link: 03_Feed_Forward_Networks.ipynb](./03_Feed_Forward_Networks.ipynb)\n",
    "\n",
    "- Write code to propagate activations through layers\n",
    "- Manually 'train' to discern features\n",
    "\n",
    "## Today\n",
    "\n",
    "- Understand the output of a neural network with 2 input neurons via visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `feed_forward` from last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(a0,w,b):\n",
    "    ''' Compute the output of a deep neural network given the input (a0) \n",
    "        and the weights (w) and biaes (b).\n",
    "    '''\n",
    "    a = a0\n",
    "    num_layers = len(b)\n",
    "    \n",
    "    # feed the input layer forward\n",
    "    for ℓ in range(num_layers):\n",
    "        z = np.dot(w[ℓ],a) + b[ℓ]\n",
    "        a = 1.0/(1.0+np.exp(-z))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a Simple Neural Network\n",
    "\n",
    "Until now we have considered a feed forward neural network that was a non-linear function of an input variable $x$ corresponding to a 3x3 grid of pixels.  This is a function on a 9-dimensional space and cannot be easily interpreted.  \n",
    "\n",
    "To gain some intuition, lets consider a **much** simpler network without a hidden layer that maps 2 input neurons to 1 output neuron, i.e.:\n",
    "\n",
    "\\begin{equation}\n",
    "f : \\mathbb{R}^2 \\to \\mathbb{R}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [2,1]\n",
    "w,b = [],[]\n",
    "for ℓ in range(1,len(N)):\n",
    "    w.append(np.array([1,1]))\n",
    "    b.append(np.array([0]))\n",
    "\n",
    "labels = [[r'$x_0$',r'$x_1$'],[r'$f(x_0,x_1)$']]\n",
    "ml4s.draw_network(N,node_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can visualize this using a heat map\n",
    "\n",
    "We need to start by generating all possible input values, in this case, all pairs of points $(x_0,x_1) \\in \\mathbb{R}^2$ in some region of space.  Let's choose a $51\\times 51$ grid with: \n",
    "\n",
    "\\begin{align}\n",
    "-1 &\\le x_0 \\le 1 \\\\\n",
    "-1 &\\le x_1 \\le 1\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 51 # the size of the grid of input values\n",
    "X0 = np.zeros([grid_size,grid_size])\n",
    "X1 = np.zeros_like(X0)\n",
    "\n",
    "# define the boundaries\n",
    "x0_min,x0_max = -1.0,1.0\n",
    "x1_min,x1_max = -1.0,1.0\n",
    "\n",
    "# and the grid size\n",
    "Δx0,Δx1 = (x0_max - x0_min)/(grid_size-1),(x1_max - x1_min)/(grid_size-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **not** the most effecient or pythonic way of doing this! \n",
    "\n",
    "An additional standard confusion is that we define *space* and *matrices* in an inconsistent manner.  For space, the first value corresponds to $x$ (horizontal position) and the second to $y$ (vertical position).  This is reversed for matrices with rows (vertical) coming first and columns (horizontal) coming second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list = []\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        X0[i,j] = x0_min + Δx0*j\n",
    "        X1[i,j] = x1_min + Δx1*i\n",
    "        \n",
    "        # saving the points for visualization purposes\n",
    "        pt_list.append([X0[i,j],X1[i,j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the points we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list = np.array(pt_list)\n",
    "plt.scatter(pt_list[:,0],pt_list[:,1], s=1)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the output of the neural network at each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.zeros_like(X0)  # this will hold the output values\n",
    "\n",
    "# we will apply our simple NN for all grid points in the box x = [-1..1,-1..1]\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        a0 = [X0[i,j],X1[i,j]]\n",
    "        a1[i,j] = feed_forward(a0,w,b)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span alert alert-warning\">\n",
    "    Note: we need to extract the 0<sup>th</sup> element of <code>feed_forward</code> as it returns an array.\n",
    "</div>\n",
    "\n",
    "Plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(X0,X1,a1, rasterized=True, cmap='Spectral_r', shading='nearest')\n",
    "plt.colorbar(label='Activation')\n",
    "plt.title('Output Activation as a function of input points in the plane')\n",
    "plt.xlabel(r'$x_0$')\n",
    "plt.ylabel(r'$x_1$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does this make sense?\n",
    "\n",
    "Think about what you would expect for a fixed set of weights and biases above based on the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can also visualize in 3D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(X0, X1, a1, rstride=1, cstride=1, cmap='Spectral_r', \n",
    "                       linewidth=0, antialiased=True, rasterized=True)\n",
    "ax.set_xlabel(r'$x_0$',labelpad=8)\n",
    "ax.set_ylabel(r'$x_1$',labelpad=8)\n",
    "ax.set_zlabel(r'$f(\\mathbf{x} )$',labelpad=8);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
