{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 494/594\n",
    "## MNIST and Softmax for Classification of Handwritten Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./include/header.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import trange,tqdm\n",
    "sys.path.append('./include')\n",
    "import ml4s\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('./include/notebook.mplstyle')\n",
    "np.set_printoptions(linewidth=120)\n",
    "ml4s.set_css_style('./include/bootstrap.css')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Time\n",
    "\n",
    "### [Notebook Link: 20_Classification.ipynb](./20_Classification.ipynb)\n",
    "\n",
    "- Studied a new type of problem involving the classification of inputs (map continue/discrete inputs into discrete outputs)\n",
    "- New cost functions: binary and categorical cross-entropy\n",
    "\n",
    "## Today\n",
    "- Classification for many classes (1-hot encoding and softmax)\n",
    "- MNIST: hand-written digits\n",
    "\n",
    "#### Categorical Cross Entropy\n",
    "\n",
    "\\begin{equation}\n",
    "C(\\boldsymbol{w}) = -\\frac{1}{N} \\sum_{n=1}^{N} \\sum_{j=1}^K y_j^{(n)} \\ln a_j^L\n",
    "\\end{equation}\n",
    "\n",
    "#### Softmax Layer\n",
    "\\begin{equation}\n",
    "a_j^L = \\frac{\\mathrm{e}^{z_j^L}}{\\sum_{k=1}^K \\mathrm{e}^{z_k^L}} \\, .\n",
    "\\end{equation}\n",
    "\n",
    "### Import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning for Digit Recognition\n",
    "\n",
    "This is an **old** and important problem (think computer vision for processing checks). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(id='FwFduRA_L6Q',width=600,height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MNIST Data Set\n",
    "\n",
    "This is a standard [(and famous)](https://en.wikipedia.org/wiki/MNIST_database) set of 60,000 training and 10,000 test images, each containing 28x28 pixels.\n",
    "\n",
    "We want to:\n",
    "\n",
    "1. Flatten the input data such that it is 1D.\n",
    "2. Rescale and cast as floats instead of integers [0-255].\n",
    "3. Turn the integer labels into 1-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# determine the properties\n",
    "rows,cols = x_train[0].shape\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and rescale\n",
    "x_train = x_train.reshape(x_train.shape[0], rows*cols).astype('float32')/255\n",
    "x_test = x_test.reshape(x_test.shape[0], rows*cols).astype('float32')/255\n",
    "\n",
    "# use a built-in function to get 1-hot encoding\n",
    "y_train_hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_hot = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the class vs. 1-hot encoding and show digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random digit in the training set\n",
    "idx = np.random.randint(low=0, high=len(x_train))\n",
    "\n",
    "print(f'class: {y_train[idx]}')\n",
    "print(f'1-hot: {y_train_hot[idx].astype(int)}')\n",
    "\n",
    "plt.matshow(x_train[idx,:].reshape(rows,cols), cmap='binary')\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that shows many digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit_array(x,y, show_prediction=False):\n",
    "    '''Expects a list of digits (x) and associated labels (y)'''\n",
    "    \n",
    "    # determine the number of rows and columns of our image array\n",
    "    num_digits = x.shape[0]\n",
    "    num_cols = int(np.sqrt(num_digits))\n",
    "    num_rows = num_digits//num_cols + 1\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=num_rows,ncols=num_cols,sharex=True,sharey=True,\n",
    "                          figsize=(num_cols,num_rows))\n",
    "    \n",
    "    # plot all the numbers\n",
    "    for i,cax in enumerate(ax.flatten()):\n",
    "        if i < num_digits:\n",
    "            cax.matshow(x[i].reshape(28,28), cmap='binary')\n",
    "            cax.axis('off')\n",
    "            if show_prediction:\n",
    "                cax.text(0.99,0.99,f'{y[i]}',horizontalalignment='right',verticalalignment='top', \n",
    "                         transform=cax.transAxes, fontsize=8, color='r')\n",
    "        else:\n",
    "            cax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "idx = np.random.randint(low=0, high=x_train.shape[0], size=100)\n",
    "plot_digit_array(x_train[idx],y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and train a neural network to learn the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "[\n",
    "    layers.Dense(128,input_shape=(rows*cols,),activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# this provides a more modern approach to the compilation\n",
    "model.compile(loss=tf.losses.CategoricalCrossentropy(), optimizer='adam', metrics=[tf.metrics.CategoricalAccuracy()])\n",
    "\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Checkpointing of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/mnist_dnn/cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "training = model.fit(x_train,y_train_hot, batch_size=batch_size, epochs=epochs,\n",
    "                     verbose=1, validation_data=(x_test,y_test_hot),callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into training history\n",
    "fig,ax = plt.subplots(2,1, sharex=True, figsize=(5,5))\n",
    "\n",
    "score = model.evaluate(x_test, y_test_hot, verbose=0);\n",
    "\n",
    "# accuracy\n",
    "ax[0].plot(training.history['categorical_accuracy'], color=colors[0])\n",
    "ax[0].plot(training.history['val_categorical_accuracy'], ls='--', color=colors[-3])\n",
    "ax[0].set_ylabel('model accuracy')\n",
    "ax[0].legend(['train', 'test'], loc='best')\n",
    "ax[0].text(0.5,0.95,f'{score[1]:.2f}',horizontalalignment='center',verticalalignment='top', \n",
    "                         transform=ax[0].transAxes)\n",
    "ax[0].set_ylim(top=1)\n",
    "\n",
    "# loss\n",
    "ax[1].plot(training.history['loss'], color=colors[0])\n",
    "ax[1].plot(training.history['val_loss'], ls='--', color=colors[-3])\n",
    "ax[1].set_ylabel('model loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_ylim(bottom=0)\n",
    "ax[1].text(0.5,0.95,f'{score[0]:.2f}',horizontalalignment='center',verticalalignment='top', \n",
    "                         transform=ax[1].transAxes)\n",
    "ax[1].legend(['train', 'test'], loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob_train = model(x_train)\n",
    "predictions_prob_test = model(x_test)\n",
    "\n",
    "predictions_train = np.argmax(predictions_prob_train,axis=1)\n",
    "predictions_test = np.argmax(predictions_prob_test,axis=1)\n",
    "\n",
    "mistakes_train = np.where(predictions_train != y_train)[0]\n",
    "mistakes_test = np.where(predictions_test != y_test)[0]\n",
    "\n",
    "num_mistakes_train,num_mistakes_test = len(mistakes_train),len(mistakes_test)\n",
    "\n",
    "print(f'Train Mistakes: {100*num_mistakes_train/x_train.shape[0]:.2f}%')\n",
    "print(f'Test Mistakes : {100*num_mistakes_test/x_test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digit_array(x_test[mistakes_test[:100]],predictions_test[mistakes_test[:100]],show_prediction=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions_test)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate softmax probabilities to see how far we are off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "idx = np.random.choice(mistakes_test)\n",
    "\n",
    "fig = plt.figure(figsize=(3,1.2*3),constrained_layout=True) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 5], figure=fig) \n",
    "\n",
    "ax = [plt.subplot(gs[0]),plt.subplot(gs[1])]\n",
    "\n",
    "ax[0].bar(range(num_classes),predictions_prob_test[idx], color='r')\n",
    "ax[0].set_xticks(range(num_classes))\n",
    "ax[0].set_yticks([]);\n",
    "ax[0].set_xlim(-0.5,9.5)\n",
    "\n",
    "ax[1].matshow(x_test[idx,:].reshape(rows,cols), cmap='binary')\n",
    "ax[1].text(0.99,0.99,f'{predictions_test[idx]}',horizontalalignment='right',verticalalignment='top', \n",
    "                         transform=ax[1].transAxes, color='r')\n",
    "ax[1].set_xticks([]);\n",
    "ax[1].set_yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
