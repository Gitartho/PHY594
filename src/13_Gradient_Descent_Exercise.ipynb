{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 494/594\n",
    "## Gradient Descent Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./include/header.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import trange,tqdm\n",
    "sys.path.append('./include')\n",
    "import ml4s\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('./include/notebook.mplstyle')\n",
    "np.set_printoptions(linewidth=120)\n",
    "ml4s.set_css_style('./include/bootstrap.css')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Time\n",
    "\n",
    "### [Notebook Link: 12_Adaptive_Gradient_Descent.ipynb](./12_Adaptive_Gradient_Descent.ipynb)\n",
    "\n",
    "- Derived a general framework (gradient descent) for optimizing functions of many parameters and saw various improvements.\n",
    "\n",
    "## Today\n",
    "\n",
    "- Explore this method to optimize a tricky function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "def plot_function(grid_1d, func, contours=50, log_contours=False, exact=[0,0]):\n",
    "    '''Make a contour plot over the region described by grid_1d for function func.'''\n",
    "    \n",
    "    # make the 2D grid\n",
    "    X,Y = np.meshgrid(grid_1d, grid_1d, indexing='xy')\n",
    "    Z = np.zeros_like(X)\n",
    "    \n",
    "    # numpy bonus exercise: can you think of a way to vectorize the following for-loop?\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X.T)):\n",
    "            Z[i, j] = func(np.array((X[i, j], Y[i, j])))  # compute function values\n",
    "    \n",
    "    fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    \n",
    "    if not log_contours:\n",
    "        ax.contour(X, Y, Z, contours, cmap='Spectral_r')\n",
    "    else:\n",
    "        ax.contour(X, Y, Z, levels=np.logspace(0, 5, 35), norm=LogNorm(), cmap='Spectral_r')\n",
    "        \n",
    "    ax.plot(*exact, '*', color='black')\n",
    "\n",
    "    ax.set_xlabel(r'$w_0$')\n",
    "    ax.set_ylabel(r'$w_1$')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    ax3d = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    \n",
    "    if log_contours:\n",
    "        Z = np.log(Z)\n",
    "        label = r'$\\ln f(\\mathbf{w}$'\n",
    "    else:\n",
    "        label = r'$f(\\mathbf{w})$'\n",
    "        \n",
    "    surf = ax3d.plot_surface(X,Y,Z, rstride=1, cstride=1, cmap='Spectral_r', \n",
    "                       linewidth=0, antialiased=True, rasterized=True)\n",
    "    \n",
    "    ax3d.plot([exact[0]], [exact[0]], [func(np.array(exact))], marker='*', ms=6, linestyle='-', color='k',lw=1, zorder=100)\n",
    "\n",
    "         \n",
    "    ax3d.set_xlabel(r'$w_0$',labelpad=8)\n",
    "    ax3d.set_ylabel(r'$w_1$',labelpad=8)\n",
    "    ax3d.set_zlabel(label,labelpad=8);\n",
    "    \n",
    "    return fig,ax,ax3d\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "def plot_trajectory(fig,ax,ax3d,w_traj,func,log_contours=False):\n",
    "    '''Plot the trajectory of a minimization.'''\n",
    "    \n",
    "    num_iter = w_traj.shape[0]\n",
    "    f_traj = np.array([func(w_traj[i,:]) for i in range(num_iter)])\n",
    "    \n",
    "    ax.plot(w_traj[0,0],w_traj[0,1], 'o', color='k', ms=6)    \n",
    "    ax.plot(w_traj[:,0],w_traj[:,1], '.', color='k', ms=1)  \n",
    "    \n",
    "    if log_contours:\n",
    "        f_traj = np.log(f_traj)\n",
    "        \n",
    "    ax3d.plot([w_traj[0,0]], [w_traj[0,1]], [f_traj[0]], marker='o', ms=6, linestyle='-', color='k',lw=1, zorder=100)\n",
    "    ax3d.plot(w_traj[:,0], w_traj[:,1], f_traj, marker='.', ms=1, linestyle='-', color='k',lw=1, zorder=100)\n",
    "    \n",
    "    ax.set_title(f'$i={i}, w=[{w[0]:.2f},{w[1]:.2f}]$' + '\\n' + f'$f(w) = {func(w):.6f}$', fontsize=14);\n",
    "    \n",
    "    return fig,ax,ax3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span alert alert-success\">\n",
    "<h2>Programming Exercise: Beale's Function </h2>\n",
    "\n",
    "1. Define a new [Beale's Function](https://en.wikipedia.org/wiki/Test_functions_for_optimization), a convex function often used to test optimization problems of the form:\n",
    "    \n",
    "\\begin{equation}\n",
    "    f(x,y) = (1.5-x+xy)^2+(2.25-x+xy^2)^2+(2.625-x+xy^3)^2\n",
    "\\end{equation}\n",
    "    \n",
    "It has a minimum at $(x,y) = (3,0.5)$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp \n",
    "from jax import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beales(X):\n",
    "    x = X[0]\n",
    "    y = X[1]\n",
    "    return # insert code here\n",
    "\n",
    "# insert code here\n",
    "db_dx = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span alert alert-success\">\n",
    "    2. Make a plot.  Add <code>log_contours=True</code> to see things better.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, ax3d = plot_function(np.linspace(-5, 5, 100), beales, exact=[3,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span alert alert-success\">\n",
    "    3. Try to find the minimum with NAG.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "η = 0.1\n",
    "γ = 0.9\n",
    "num_iter = 100\n",
    "\n",
    "# I choose a specific starting point (-2.5,2)\n",
    "w = np.array([-2.5,2])\n",
    "\n",
    "ax.plot(*w, marker='.', color='k', ms=15)  \n",
    "\n",
    "w_traj = np.zeros([num_iter,2])\n",
    "w_traj[0,:] = w\n",
    "\n",
    "v = np.zeros(2)\n",
    "\n",
    "for i in range(1,num_iter):\n",
    "    \n",
    "    # perform the NAG update\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span alert alert-warning\">\n",
    "    If your code fails, try playing with the learning rate $\\eta$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, ax3d = plot_function(np.linspace(-5, 5, 100), beales, log_contours=True, exact=[3,0.5])\n",
    "fig, ax, ax3d  = plot_trajectory(fig,ax,ax3d,w_traj,beales,log_contours=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span alert alert-success\">\n",
    "    4. Repeat with ADAM.  Experiment with different learning rates.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "β1 = 0.9\n",
    "β2 = 0.999\n",
    "ϵ = 1.0E-8\n",
    "η = 5.0E-3\n",
    "γ = 0.9\n",
    "num_iter = 10**3\n",
    "\n",
    "# if you want you can play with some different initial points\n",
    "#w = np.random.uniform(low=-3,high=3,size=2)\n",
    "\n",
    "w = np.array([-2.5,2])\n",
    "\n",
    "w_traj = np.zeros([num_iter,2])\n",
    "w_traj[0,:] = w\n",
    "\n",
    "m = np.zeros(2)\n",
    "v = np.zeros(2)\n",
    "\n",
    "for i in range(1,num_iter):\n",
    "        \n",
    "    # Implement ADAM\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, ax3d = plot_function(np.linspace(-5, 5, 100), beales, log_contours=True, exact=[3,0.5])\n",
    "fig, ax, ax3d  = plot_trajectory(fig,ax,ax3d,w_traj,beales,log_contours=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
