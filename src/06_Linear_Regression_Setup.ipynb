{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 494/594\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./include/header.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import trange,tqdm\n",
    "sys.path.append('./include')\n",
    "import ml4s\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('./include/notebook.mplstyle')\n",
    "np.set_printoptions(linewidth=120)\n",
    "ml4s.set_css_style('./include/bootstrap.css')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Time\n",
    "\n",
    "### [Notebook Link: 05_Batch_Processing.ipynb](./05_Batch_Processing.ipynb)\n",
    "\n",
    "- Explored linear algebra in `numpy` for batch processing of samples\n",
    "- Observed massive speedups! Use array operations whenever possible\n",
    "\n",
    "## Today\n",
    "- Cost functions and formulating a machine learning task as an optimization problem\n",
    "- Understand linear regression \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Steady-State One-Dimensional Heat Conduction\n",
    "\n",
    "Fourier's law of heat conduction for a bar of constant cross-sectional area connected between two reservoirs in the steady-state limit gives a simple differential equation for the spatial dependence of the temperature $T$:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d^2 T(x)}{d x^2} &= 0 \\\\\n",
    "\\frac{d T(x)}{dx} &= w \\\\\n",
    "T(x) &= w x + b \n",
    "\\end{align}\n",
    "\n",
    "Load experimental data from `../data/rod_temperature.dat` using the very convenient `np.loadtxt()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../data/rod_temperature.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,T,ΔT = np.loadtxt('../data/rod_temperature.dat', unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x,T,ΔT, marker='o', linestyle='')\n",
    "plt.xlabel('x  (m)')\n",
    "plt.ylabel('T  (°C)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect a linear relationship from Physics!  Let's start with a random guess, and try to fit some other lines by eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "b = []\n",
    "x_fit = np.linspace(np.min(x),np.max(x),100)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(10,3.5))\n",
    "\n",
    "for i in range(len(w)):\n",
    "    ax[0].plot(x_fit,w[i]*x_fit + b[i], color=colors[i+1])\n",
    "    ax[1].plot(w[i],b[i], 'o', color=colors[i+1])\n",
    "    \n",
    "ax[0].plot(x,T, 'o', ms=6)\n",
    "ax[0].set_xlabel('x (m)')\n",
    "ax[0].set_ylabel('T (°C)')\n",
    "ax[0].set_title('Data Space')\n",
    "\n",
    "ax[1].set_xlabel('w (°C/m)')\n",
    "ax[1].set_ylabel('b (°C)')\n",
    "ax[1].set_title('Weight Space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Want to predict a scalar $T$ as a function of scalar $x$ given a dataset of pairs $\\{(x^{(n)},T^{(n)})\\}_{n=1}^N$.  Here the $x^{(n)}$ are inputs and the $T^{(n)}$ are targets or observations. From physics, we have a model:\n",
    "\n",
    "\\begin{equation}\n",
    "F(x) = w x + b\n",
    "\\end{equation}\n",
    "\n",
    "i.e. $F^{(n)} = w x^{(n)} + b$.\n",
    "\n",
    "We can think of this as the simplest possible **shallow** neural network (no hidden layer) and non non-linearity, i.e. $a(x) = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[r'$x$'],[r'$F(x) = wx + b$']]\n",
    "ml4s.draw_network([1,1],weights=[np.array(['w'])],biases=[np.array(['b'])], node_labels=labels, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to *learn* the **parameters** (weight $w$ and bias $b$) based on the **prediction** $F$ (here a linear function).  We will do this by minimizing (optimizing) a **loss** function. For a single data point (observation) this is defined to be:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}^{(n)} = \\frac{1}{2} \\lvert \\lvert F^{(n)} - T^{(n)} \\rvert \\rvert^2\n",
    "\\end{equation}\n",
    "\n",
    "which quantifies the goodness of fit over our **hypothesis** space (all values of the parameters).  \n",
    "\n",
    "$F-T$ is the residual, we want to make this as small as possible, which we can do by computing the **Cost** function, the loss function averaged over all training examples (input data):\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\mathcal{C} = \\frac{1}{2N} \\sum_{n=1}^N  \\lvert \\lvert F^{(n)} - T^{(n)} \\rvert \\rvert^2\n",
    "}\n",
    "\\end{equation}\n",
    "\n",
    "Let's use what we learned last time about batch processing to look at this loss function. Here, our input samples are the individual values of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a specific hypothesis (i.e. individual values of w and b)\n",
    "C_hyp = []\n",
    "for i in range(len(w)):\n",
    "    F = np.dot(x,w[i]) + b[i]\n",
    "    C_hyp.append(0.5*np.average((F-T)**2))\n",
    "print(C_hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can do this over the entire space of weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 100 \n",
    "weights,biases = np.meshgrid(np.linspace(400,1200,grid_size),np.linspace(-1,18,grid_size))\n",
    "C = np.zeros_like(weights)\n",
    "\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        F = np.dot(x,weights[i,j]) + biases[i,j]\n",
    "        C[i,j] = 0.5*np.average((F-T)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contour(weights,biases,C, cmap='Spectral_r', levels=100)\n",
    "\n",
    "for i in range(len(w)):\n",
    "    plt.plot(w[i],b[i], 'o', ms=10, color=colors[i+1])\n",
    "\n",
    "plt.xlabel('w / (°C/m)')\n",
    "plt.ylabel('b / °C')\n",
    "plt.colorbar(label='Cost Function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(weights, biases,C , rstride=1, cstride=1, cmap='Spectral_r', \n",
    "                       linewidth=0, antialiased=True, rasterized=True)\n",
    "\n",
    "# plot the points\n",
    "for i in range(len(w)):\n",
    "    ax.plot3D(w[i],b[i],C_hyp[i], 'o', color='k', ms=10)\n",
    "\n",
    "ax.set_xlabel('w (°C/m)',labelpad=8)\n",
    "ax.set_ylabel('b (°C)',labelpad=8)\n",
    "ax.set_zlabel('C(w,b)',labelpad=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we identify the minimum of this cost function to extract the *best* parameters for our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
