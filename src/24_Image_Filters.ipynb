{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 494/594\n",
    "## Image Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./include/header.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import trange,tqdm\n",
    "sys.path.append('./include')\n",
    "import ml4s\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('./include/notebook.mplstyle')\n",
    "np.set_printoptions(linewidth=120)\n",
    "ml4s.set_css_style('./include/bootstrap.css')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "π = np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Time\n",
    "\n",
    "### [Notebook Link: 23_MNIST_Generalization.ipynb](./23_MNIST_Generalization.ipynb)\n",
    "\n",
    "- Explored the robustness and generalizability of our classification model.\n",
    "- Investigated translations and rotations of digits.\n",
    "\n",
    "## Today\n",
    "\n",
    "- Image filters: local feature detection and sampling\n",
    "\n",
    "### Generalization of our Deep Neural Network for Digit Recognition\n",
    "\n",
    "Last time we saw that while we could train a network to have less than 2% error rate, it failed to generalize to the simple case of translating or rotating digits.  This is mostly due to the fact that the MNIST data set has been pre-processed, such that all digits are in the center are are aligned.\n",
    "\n",
    "We discussed building a set of synthetic training data by rotating and translating the digits.  This is a **good idea** and is often done in practice.  However, this can drastically increase the training time.\n",
    "\n",
    "Recall that we input our `28x28` pixel images of digits as a flattened array of 784.  When doing this we are essentially throwing away spatial correlations in the image.  Convolutional Networks (*ConvNets*) solve both the time and correlation problem and are the state of the art for classification problems involving images.  The first step is to introduce what we mean by the term *convolution*.\n",
    "\n",
    "#### Convolutions\n",
    "\n",
    "Given a function $y(\\boldsymbol{x})$ we can apply a convolution via a *kernel* $K(\\boldsymbol{x})$ by integrating over our domain:\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{y}(\\boldsymbol{x}) = \\int K(\\boldsymbol{x}-\\boldsymbol{x}^\\prime) y(\\boldsymbol{x}^\\prime) d\\boldsymbol{x}^\\prime\n",
    "\\end{equation}\n",
    "\n",
    "where $K(\\boldsymbol{x})$ is usually a *local* function, i.e. it decays rapdily with distance.  If it is short-ranged enough, we can replace the integral with a sum over points.  Supose we intepret $y(\\boldsymbol{x})$ as matrix of pixels $y_{ij}$, then we can write:\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{y}_{ij} = \\sum_{\\mu,\\nu} K_{\\mu\\nu} y_{i+\\mu j+\\nu} \n",
    "\\end{equation}\n",
    "\n",
    "where we have assumed unit grid spacing.  Here, $\\mu$ and $\\nu$ run over some small range known as the **receptive field size** or **kernel size** often labeled $F$. Let's explore the types of convolutions we can do on a simple image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerT = plt.imread('../data/power_T.png')[:,:,1]\n",
    "powerT -= np.min(powerT)\n",
    "powerT /= np.max(powerT)\n",
    "\n",
    "# flip pixels\n",
    "powerT = np.abs(1-powerT)\n",
    "rows,cols = powerT.shape\n",
    "\n",
    "plt.matshow(powerT, cmap='binary')\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothing\n",
    "\n",
    "We can apply a Gaussian at each point of the image\n",
    "\n",
    "\\begin{equation}\n",
    "K_{\\mu \\nu} = \\frac{1}{F^2}\\mathrm{e}^{-\\mu^2 - \\nu^2}\n",
    "\\end{equation}\n",
    "\n",
    "and lets use a kernel size of $F=5$, i.e. $\\mu,\\nu \\in \\{-2,-1,0,1,2\\}$ in our convolution. We obviously need to worry about what we do at the boundary.  The simplest thing is just to pad with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.pad(powerT,(1,1),mode='edge')\n",
    "ỹ = np.zeros_like(powerT)\n",
    "F = 5\n",
    "for i in range(1,rows):\n",
    "    for j in range(1,cols):\n",
    "        Ky = 0.0\n",
    "        for μ in range(-2,3,1):\n",
    "            for ν in range(-2,3,1):\n",
    "                Ky += np.exp(-μ**2-ν**2)*y[i+μ,j+ν]\n",
    "        ỹ[i-1,j-1] = Ky/F**2\n",
    "ỹ /= np.max(ỹ)  \n",
    "\n",
    "plt.matshow(ỹ, cmap='binary')\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection\n",
    "\n",
    "Edges can be found by modifying our above kernel to use an odd function:\n",
    "\n",
    "\\begin{equation}\n",
    "K_{\\mu\\nu} = \\frac{1}{F^2}\\mathrm{e}^{-\\mu^2 - \\nu^2} \\sin \\left[\\frac{\\pi}{2} (\\mu-\\nu)\\right]\n",
    "\\end{equation}\n",
    "\n",
    "where we will choose $F=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.pad(powerT,(1,1),constant_values=0)\n",
    "ỹ = np.zeros_like(powerT)\n",
    "F = 3\n",
    "for i in range(1,rows):\n",
    "    for j in range(1,cols):\n",
    "        Ky = 0.0\n",
    "        for μ in range(-1,2,1):\n",
    "            for ν in range(-1,2,1):\n",
    "                Ky += np.exp(-μ**2-ν**2)*np.sin((π/2)*(μ-ν))*y[i+μ,j+ν]\n",
    "        ỹ[i-1,j-1] = Ky/F**2\n",
    "ỹ /= np.max(ỹ)     \n",
    "\n",
    "plt.matshow(ỹ, cmap='binary')\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does this work?  The kernel acts as an approximation to the spatial derivative and is commonly used in image processing where it is known as the [Gabor filter](https://en.wikipedia.org/wiki/Gabor_filter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor(x,y):\n",
    "    return np.exp(-x**2-y**2)*np.sin(0.5*π*(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
    "X,Y = np.meshgrid(np.linspace(-2,2,100),np.linspace(-2,2,100), indexing='ij')\n",
    "ax[0].imshow(gabor(X,Y), cmap='coolwarm', extent=[-2,2,-2,2], origin='lower')\n",
    "ax[0].set_xlabel('x')\n",
    "ax[0].set_ylabel('x')\n",
    "\n",
    "G = np.array([[0,1,0],[1,0,-1],[0,-1,0]])\n",
    "ax[1].imshow(G, cmap='coolwarm')\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "Another important image processing technique is sub-sampling via either *max* or *average* pooling.  We downsample an image by replacing a group of pixels (`pool_size x pool_size`) with their maximum or average.  This changes the number of pixels in the output image. \n",
    "\n",
    "Let's take `pool_size = 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = 10\n",
    "y = np.zeros([rows//pool_size,cols//pool_size])\n",
    "for i in range(y.shape[0]):\n",
    "    for j in range(y.shape[1]):\n",
    "        y[i,j] = np.max(powerT[i*pool_size:(i+1)*pool_size,j*pool_size:(j+1)*pool_size])\n",
    "        \n",
    "plt.matshow(y, cmap='binary')\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up Sampling\n",
    "\n",
    "We can perform the opposite action, and enlarge the image by copying a value onto a grid.  The image will look the same, (i.e. no change in features) but the number of pixels is now rescaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_size = 10\n",
    "y_up = np.zeros([up_size*y.shape[0],up_size*y.shape[1]])\n",
    "for i in range(y.shape[0]):\n",
    "    for j in range(y.shape[1]):\n",
    "        y_up[i*up_size:(i+1)*up_size,j*up_size:(j+1)*up_size] = y[i,j]\n",
    "        \n",
    "plt.matshow(y_up, cmap='binary')\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
